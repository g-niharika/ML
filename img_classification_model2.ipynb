{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7v9Yw-HXdPJD"
   },
   "source": [
    "## **PART-2**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMR2LXTZ15a8"
   },
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7dDFM1LKQ_4P",
    "outputId": "225f5097-94fb-405e-8baf-f6dabf705b76",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "transform = torchvision.transforms.Compose( [torchvision.transforms.ToTensor(),\n",
    "torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_Hqe4r4cRO95"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  plt.figure(figsize = (3,3))\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iv0l_7pBRndH"
   },
   "outputs": [],
   "source": [
    "total_size = len(trainset)\n",
    "train_size = int(0.9 * total_size)\n",
    "val_size = total_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RGU00SdKTJBV"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n3Y_f-XRTLgr"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Cm8jzT8gUItv",
    "outputId": "7c5f63ee-c740-4243-c3bd-17f724a5bed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 1.6067 | Train Accuracy: 41.49%\n",
      "Validation Loss: 1.2816 | Validation Accuracy: 53.64%\n",
      "Test Accuracy: 53.62%\n",
      "Epoch 2/10:\n",
      "Train Loss: 1.1851 | Train Accuracy: 57.74%\n",
      "Validation Loss: 1.2096 | Validation Accuracy: 56.90%\n",
      "Test Accuracy: 57.01%\n",
      "Epoch 3/10:\n",
      "Train Loss: 1.0065 | Train Accuracy: 64.38%\n",
      "Validation Loss: 1.0012 | Validation Accuracy: 64.20%\n",
      "Test Accuracy: 64.67%\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.8803 | Train Accuracy: 69.06%\n",
      "Validation Loss: 0.9072 | Validation Accuracy: 67.94%\n",
      "Test Accuracy: 68.15%\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.7824 | Train Accuracy: 72.42%\n",
      "Validation Loss: 0.9374 | Validation Accuracy: 67.28%\n",
      "Test Accuracy: 67.24%\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.6840 | Train Accuracy: 75.82%\n",
      "Validation Loss: 0.9158 | Validation Accuracy: 68.48%\n",
      "Test Accuracy: 68.08%\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.5936 | Train Accuracy: 78.95%\n",
      "Validation Loss: 0.9312 | Validation Accuracy: 69.50%\n",
      "Test Accuracy: 69.07%\n",
      "Epoch 8/10:\n",
      "Train Loss: 0.5002 | Train Accuracy: 82.33%\n",
      "Validation Loss: 0.9618 | Validation Accuracy: 69.30%\n",
      "Test Accuracy: 69.00%\n",
      "Epoch 9/10:\n",
      "Train Loss: 0.4245 | Train Accuracy: 84.85%\n",
      "Validation Loss: 1.0471 | Validation Accuracy: 70.00%\n",
      "Test Accuracy: 68.79%\n",
      "Epoch 10/10:\n",
      "Train Loss: 0.3530 | Train Accuracy: 87.44%\n",
      "Validation Loss: 1.1274 | Validation Accuracy: 68.68%\n",
      "Test Accuracy: 68.11%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, img_input):\n",
    "        img_input = self.conv1(img_input)\n",
    "        img_input = self.relu1(img_input)\n",
    "        img_input = self.pool1(img_input)\n",
    "        img_input = self.conv2(img_input)\n",
    "        img_input = self.relu2(img_input)\n",
    "        img_input = self.pool2(img_input)\n",
    "        img_input = img_input.view(img_input.size(0), -1)  # Flatten\n",
    "        img_input = self.fc1(img_input)\n",
    "        img_input = self.relu3(img_input)\n",
    "        img_input = self.fc2(img_input)\n",
    "        return img_input\n",
    "\n",
    "cnn_model = SimpleCNN()\n",
    "criterion_lf = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def train(cnn_model, train_loader, criterion_lf, optimizer, processor):\n",
    "    cnn_model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_op = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(processor), labels.to(processor)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss_cal = criterion_lf(outputs, labels)\n",
    "        loss_cal.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss_cal.item()\n",
    "        _, predicted_val = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct_op += predicted_val.eq(labels).sum().item()\n",
    "    train_accuracy = 100.0 * correct_op / total\n",
    "    return total_loss / len(train_loader), train_accuracy\n",
    "\n",
    "def validate(cnn_model, val_loader,criterion_lf, processor):\n",
    "    cnn_model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_op = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(processor), labels.to(processor)\n",
    "            outputs = cnn_model(inputs)\n",
    "            loss_cal = criterion_lf(outputs, labels)\n",
    "            total_loss += loss_cal.item()\n",
    "            _, predicted_val = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_op += predicted_val.eq(labels).sum().item()\n",
    "    val_accuracy = 100.0 * correct_op / total\n",
    "    return total_loss / len(val_loader), val_accuracy\n",
    "\n",
    "def test(cnn_model, test_loader, processor):\n",
    "    cnn_model.eval()\n",
    "    correct_op = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(processor), labels.to(processor)\n",
    "            outputs = cnn_model(inputs)\n",
    "            _, predicted_val = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct_op += predicted_val.eq(labels).sum().item()\n",
    "    test_accuracy = 100.0 * correct_op / total\n",
    "    return test_accuracy\n",
    "\n",
    "processor = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(cnn_model.to('cuda'), train_loader, criterion_lf, optimizer, processor)\n",
    "    val_loss, val_accuracy = validate(cnn_model.to('cuda'), val_loader, criterion_lf, processor)\n",
    "    test_accuracy = test(cnn_model.to('cuda'), test_loader, processor)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gkyysY0qWlau",
    "outputId": "564e7f8f-8485-4bde-d17f-178192f4ce3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1/10:\n",
      "Train Loss: 1.9999 | Train Accuracy: 24.95%\n",
      "Validation Loss: 1.7391 | Validation Accuracy: 35.63%\n",
      "Test Accuracy: 36.22%\n",
      "Epoch 2/10:\n",
      "Train Loss: 1.5383 | Train Accuracy: 43.11%\n",
      "Validation Loss: 1.4079 | Validation Accuracy: 47.80%\n",
      "Test Accuracy: 47.97%\n",
      "Epoch 3/10:\n",
      "Train Loss: 1.2755 | Train Accuracy: 53.30%\n",
      "Validation Loss: 1.2161 | Validation Accuracy: 55.52%\n",
      "Test Accuracy: 55.37%\n",
      "Epoch 4/10:\n",
      "Train Loss: 1.0723 | Train Accuracy: 61.52%\n",
      "Validation Loss: 0.9677 | Validation Accuracy: 65.56%\n",
      "Test Accuracy: 65.80%\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.9237 | Train Accuracy: 67.04%\n",
      "Validation Loss: 0.8958 | Validation Accuracy: 68.18%\n",
      "Test Accuracy: 68.56%\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.8135 | Train Accuracy: 71.41%\n",
      "Validation Loss: 0.7872 | Validation Accuracy: 71.98%\n",
      "Test Accuracy: 72.95%\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.7377 | Train Accuracy: 74.12%\n",
      "Validation Loss: 0.7511 | Validation Accuracy: 73.07%\n",
      "Test Accuracy: 73.73%\n",
      "Epoch 8/10:\n",
      "Train Loss: 0.6621 | Train Accuracy: 76.71%\n",
      "Validation Loss: 0.7281 | Validation Accuracy: 74.81%\n",
      "Test Accuracy: 75.37%\n",
      "Epoch 9/10:\n",
      "Train Loss: 0.6042 | Train Accuracy: 79.05%\n",
      "Validation Loss: 0.6969 | Validation Accuracy: 75.63%\n",
      "Test Accuracy: 76.39%\n",
      "Epoch 10/10:\n",
      "Train Loss: 0.5623 | Train Accuracy: 80.48%\n",
      "Validation Loss: 0.6235 | Validation Accuracy: 77.99%\n",
      "Test Accuracy: 78.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "total_size = len(trainset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class CNN5Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN5Layers, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        pool1_output_size_calc = (32 - 2 + 2 * 1) // 2 + 1\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        pool2_output_size_calc = (pool1_output_size_calc - 2 + 2 * 1) // 2 + 1\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        pool3_output_size_calc = (pool2_output_size_calc - 2 + 2 * 1) // 2 + 1\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        pool4_output_size_calc = (pool3_output_size_calc - 2 + 2 * 1) // 2 + 1\n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(8192, 4096)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, img_input):\n",
    "        img_input = self.conv1(img_input)\n",
    "        img_input = self.relu1(img_input)\n",
    "        img_input = self.pool1(img_input)\n",
    "        img_input = self.conv2(img_input)\n",
    "        img_input = self.relu2(img_input)\n",
    "        img_input = self.pool2(img_input)\n",
    "        img_input = self.conv3(img_input)\n",
    "        img_input = self.relu3(img_input)\n",
    "        img_input = self.conv4(img_input)\n",
    "        img_input = self.relu4(img_input)\n",
    "        img_input = self.conv5(img_input)\n",
    "        img_input = self.relu5(img_input)\n",
    "        img_input = self.pool5(img_input)\n",
    "        img_input = img_input.view(img_input.size(0), -1)  # Flatten\n",
    "        img_input = self.fc1(img_input)\n",
    "        img_input = self.relu6(img_input)\n",
    "        img_input = self.fc2(img_input)\n",
    "        img_input = self.relu7(img_input)\n",
    "        img_input = self.fc3(img_input)\n",
    "        return img_input\n",
    "\n",
    "cnn_model = CNN5Layers()\n",
    "criterion_lf = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "processor = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(cnn_model.to('cuda'), train_loader, criterion_lf, optimizer, processor)\n",
    "    val_loss, val_accuracy = validate(cnn_model.to('cuda'), val_loader, criterion_lf, processor)\n",
    "    test_accuracy = test(cnn_model.to('cuda'), test_loader, processor)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "G50XAts115bJ",
    "outputId": "5878ec40-dac7-4b3e-c047-e3e0d37111f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "Train Loss: 2.2693 | Train Accuracy: 12.34%\n",
      "Validation Loss: 2.0439 | Validation Accuracy: 22.50%\n",
      "Test Accuracy: 22.16%\n",
      "Epoch 2/20:\n",
      "Train Loss: 1.9462 | Train Accuracy: 24.25%\n",
      "Validation Loss: 1.8077 | Validation Accuracy: 30.11%\n",
      "Test Accuracy: 30.53%\n",
      "Epoch 3/20:\n",
      "Train Loss: 1.7005 | Train Accuracy: 34.61%\n",
      "Validation Loss: 1.5240 | Validation Accuracy: 42.97%\n",
      "Test Accuracy: 42.85%\n",
      "Epoch 4/20:\n",
      "Train Loss: 1.4803 | Train Accuracy: 45.16%\n",
      "Validation Loss: 1.3355 | Validation Accuracy: 51.28%\n",
      "Test Accuracy: 51.06%\n",
      "Epoch 5/20:\n",
      "Train Loss: 1.2831 | Train Accuracy: 53.71%\n",
      "Validation Loss: 1.1684 | Validation Accuracy: 57.42%\n",
      "Test Accuracy: 57.14%\n",
      "Epoch 6/20:\n",
      "Train Loss: 1.1378 | Train Accuracy: 59.56%\n",
      "Validation Loss: 1.1299 | Validation Accuracy: 59.58%\n",
      "Test Accuracy: 59.55%\n",
      "Epoch 7/20:\n",
      "Train Loss: 1.0092 | Train Accuracy: 64.25%\n",
      "Validation Loss: 0.9650 | Validation Accuracy: 66.46%\n",
      "Test Accuracy: 67.37%\n",
      "Epoch 8/20:\n",
      "Train Loss: 0.9099 | Train Accuracy: 68.31%\n",
      "Validation Loss: 0.8131 | Validation Accuracy: 71.07%\n",
      "Test Accuracy: 72.29%\n",
      "Epoch 9/20:\n",
      "Train Loss: 0.8141 | Train Accuracy: 72.14%\n",
      "Validation Loss: 0.7632 | Validation Accuracy: 73.23%\n",
      "Test Accuracy: 73.83%\n",
      "Epoch 10/20:\n",
      "Train Loss: 0.7497 | Train Accuracy: 74.50%\n",
      "Validation Loss: 0.6903 | Validation Accuracy: 76.66%\n",
      "Test Accuracy: 76.36%\n",
      "Epoch 11/20:\n",
      "Train Loss: 0.6835 | Train Accuracy: 76.83%\n",
      "Validation Loss: 0.6421 | Validation Accuracy: 77.98%\n",
      "Test Accuracy: 78.46%\n",
      "Epoch 12/20:\n",
      "Train Loss: 0.6286 | Train Accuracy: 78.66%\n",
      "Validation Loss: 0.6648 | Validation Accuracy: 77.70%\n",
      "Test Accuracy: 77.06%\n",
      "Epoch 13/20:\n",
      "Train Loss: 0.5876 | Train Accuracy: 80.28%\n",
      "Validation Loss: 0.6026 | Validation Accuracy: 79.20%\n",
      "Test Accuracy: 80.00%\n",
      "Epoch 14/20:\n",
      "Train Loss: 0.5541 | Train Accuracy: 81.49%\n",
      "Validation Loss: 0.5638 | Validation Accuracy: 80.77%\n",
      "Test Accuracy: 81.05%\n",
      "Epoch 15/20:\n",
      "Train Loss: 0.5145 | Train Accuracy: 82.84%\n",
      "Validation Loss: 0.5553 | Validation Accuracy: 81.13%\n",
      "Test Accuracy: 81.72%\n",
      "Epoch 16/20:\n",
      "Train Loss: 0.4851 | Train Accuracy: 83.65%\n",
      "Validation Loss: 0.4990 | Validation Accuracy: 83.17%\n",
      "Test Accuracy: 83.07%\n",
      "Epoch 17/20:\n",
      "Train Loss: 0.4561 | Train Accuracy: 84.66%\n",
      "Validation Loss: 0.5096 | Validation Accuracy: 83.04%\n",
      "Test Accuracy: 82.97%\n",
      "Epoch 18/20:\n",
      "Train Loss: 0.4333 | Train Accuracy: 85.35%\n",
      "Validation Loss: 0.5016 | Validation Accuracy: 83.24%\n",
      "Test Accuracy: 83.03%\n",
      "Epoch 19/20:\n",
      "Train Loss: 0.4136 | Train Accuracy: 86.17%\n",
      "Validation Loss: 0.5315 | Validation Accuracy: 82.27%\n",
      "Test Accuracy: 82.93%\n",
      "Epoch 20/20:\n",
      "Train Loss: 0.3974 | Train Accuracy: 86.58%\n",
      "Validation Loss: 0.4963 | Validation Accuracy: 83.13%\n",
      "Test Accuracy: 83.66%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_input):\n",
    "        img_input = self.conv_layers(img_input)\n",
    "        img_input = self.fc_layers(img_input)\n",
    "        return img_input\n",
    "\n",
    "cnn_model = CustomCNN()\n",
    "criterion_lf = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.9)\n",
    "processor = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(cnn_model.to('cuda'), train_loader, criterion_lf, optimizer, processor)\n",
    "    val_loss, val_accuracy = validate(cnn_model.to('cuda'), val_loader, criterion_lf, processor)\n",
    "    test_accuracy = test(cnn_model.to('cuda'), test_loader, processor)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCjzSZSfYs0s"
   },
   "source": [
    "**Methods and Results:**\n",
    "The first model, which consists of two CNN layers, achieved a testing accuracy of 68.11%.\n",
    "\n",
    "In the second model, the number of layers was increased to five CNN layers, resulting in a significant improvement in accuracy by approximately 10-11%, with the second model achieving an accuracy of around 78.45%.\n",
    "\n",
    "For the third model, six CNN layers were utilized, and a dropout layer was incorporated. This model achieved an even higher accuracy of 83.66%."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
